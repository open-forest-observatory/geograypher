{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "# Library imports\n",
    "from geograypher.cameras.derived_cameras import MetashapeCameraSet\n",
    "from geograypher.meshes import TexturedPhotogrammetryMesh\n",
    "from geograypher.utils.visualization import show_segmentation_labels\n",
    "from geograypher.constants import (\n",
    "    EXAMPLE_LABELS_FILENAME,\n",
    "    EXAMPLE_MESH_FILENAME,\n",
    "    EXAMPLE_CAMERAS_FILENAME,\n",
    "    EXAMPLE_DTM_FILE,\n",
    "    EXAMPLE_IMAGE_FOLDER,\n",
    "    EXAMPLE_LABELED_MESH_FILENAME,\n",
    "    EXAMPLE_RENDERED_LABELS_FOLDER,\n",
    "    EXAMPLE_IDS_TO_LABELS,\n",
    "    EXAMPLE_LABEL_COLUMN_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set constants\n",
    "You should be able to define most of the behavior from these constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters to control the outputs\n",
    "# Repeat the labeling process\n",
    "RETEXTURE = True\n",
    "# Points less than this height above the DTM are considered ground\n",
    "# Something is off about the elevation between the mesh and the DTM, this should be a threshold in meters above ground\n",
    "HEIGHT_ABOVE_GROUND_THRESH = 2\n",
    "# The image is downsampled to this fraction for accelerated rendering\n",
    "RENDER_IMAGE_SCALE = 1\n",
    "# Portions of the mesh within this distance of the labels are used for rendering\n",
    "MESH_BUFFER_RADIUS_METER = 20\n",
    "# Cameras within this radius of the annotations are used for training\n",
    "CAMERAS_BUFFER_RADIUS_METERS = 50\n",
    "# Downsample target\n",
    "DOWNSAMPLE_TARGET = 1\n",
    "\n",
    "## Define the inputs\n",
    "# The mapping between integer class IDs and string class names\n",
    "IDS_TO_LABELS = EXAMPLE_IDS_TO_LABELS\n",
    "# The input labels\n",
    "LABELS_FILENAME = EXAMPLE_LABELS_FILENAME\n",
    "# Render data from this column in the geofile to each image\n",
    "LABEL_COLUMN_NAME = EXAMPLE_LABEL_COLUMN_NAME\n",
    "# The mesh exported from Metashape\n",
    "MESH_FILENAME = EXAMPLE_MESH_FILENAME\n",
    "# The camera file exported from Metashape\n",
    "CAMERAS_FILENAME = EXAMPLE_CAMERAS_FILENAME\n",
    "# The digital elevation map exported by Metashape\n",
    "DTM_FILE = EXAMPLE_DTM_FILE\n",
    "# The image folder used to create the Metashape project\n",
    "IMAGE_FOLDER = EXAMPLE_IMAGE_FOLDER\n",
    "\n",
    "## Define the intermediate results\n",
    "# Processed geo file\n",
    "# Where to save the mesh after labeling\n",
    "LABELED_MESH_FILENAME = EXAMPLE_LABELED_MESH_FILENAME\n",
    "# Where to save the rendering label images\n",
    "RENDER_FOLDER = EXAMPLE_RENDERED_LABELS_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial processing\n",
    "\n",
    "Preprocess the geospatial data to be as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "gdf = gpd.read_file(LABELS_FILENAME)\n",
    "# Show\n",
    "gdf.plot(LABEL_COLUMN_NAME, legend=True, vmin=-0.5, vmax=9.5, cmap=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the mesh and read texture from geopolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a labeled version of the mesh from the field data\n",
    "# if not present or requested\n",
    "if not Path(LABELED_MESH_FILENAME).is_file() or RETEXTURE:\n",
    "    # Load the downsampled mesh and apply the texture from the vector file\n",
    "    mesh = TexturedPhotogrammetryMesh(\n",
    "        MESH_FILENAME,\n",
    "        downsample_target=DOWNSAMPLE_TARGET,\n",
    "        texture=LABELS_FILENAME,\n",
    "        ROI=LABELS_FILENAME,\n",
    "        ROI_buffer_meters=MESH_BUFFER_RADIUS_METER,\n",
    "        IDs_to_labels=IDS_TO_LABELS,\n",
    "        texture_column_name=LABEL_COLUMN_NAME,\n",
    "        transform_filename=CAMERAS_FILENAME,\n",
    "    )\n",
    "    # Get the vertex textures from the mesh\n",
    "    texture_verts = mesh.get_texture(\n",
    "        request_vertex_texture=True, try_verts_faces_conversion=False\n",
    "    )\n",
    "    mesh.label_ground_class(\n",
    "        DTM_file=DTM_FILE,\n",
    "        height_above_ground_threshold=HEIGHT_ABOVE_GROUND_THRESH,\n",
    "        only_label_existing_labels=True,\n",
    "        ground_class_name=\"GROUND\",\n",
    "        ground_ID=np.nan, # This means that no ground label will be included\n",
    "        set_mesh_texture=True,\n",
    "    )\n",
    "\n",
    "    mesh.save_mesh(LABELED_MESH_FILENAME, save_vert_texture=True)\n",
    "else:\n",
    "    mesh = TexturedPhotogrammetryMesh(\n",
    "        LABELED_MESH_FILENAME, transform_filename=CAMERAS_FILENAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a set of cameras and subset them to the region around annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create camera set\n",
    "camera_set = MetashapeCameraSet(CAMERAS_FILENAME, IMAGE_FOLDER)\n",
    "# Extract cameras near the training data\n",
    "training_camera_set = camera_set.get_subset_ROI(\n",
    "    ROI=LABELS_FILENAME, buffer_radius=CAMERAS_BUFFER_RADIUS_METERS\n",
    ")\n",
    "# Show the camera set\n",
    "training_camera_set.vis(force_xvfb=True, frustum_scale=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can include the camera set, but it's cleaner without it\n",
    "mesh.vis(camera_set=None, force_xvfb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render the labels onto the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh.save_renders(\n",
    "    camera_set=training_camera_set,\n",
    "    render_image_scale=RENDER_IMAGE_SCALE,\n",
    "    save_native_resolution=True,\n",
    "    output_folder=RENDER_FOLDER,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show some of the rendered labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_segmentation_labels(\n",
    "    label_folder=RENDER_FOLDER,\n",
    "    image_folder=IMAGE_FOLDER,\n",
    "    num_show=10,\n",
    "    label_suffix=\".png\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geograypher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
